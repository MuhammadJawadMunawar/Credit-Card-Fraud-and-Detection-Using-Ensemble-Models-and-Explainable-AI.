{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Interpretability Analysis (SHAP & LIME)"
      ],
      "metadata": {
        "id": "GchoBP8wc45O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEwguCIeaxoL"
      },
      "outputs": [],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5_interpretability_analysis.ipynb\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4hZ8eBRTc_AI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 Load the best model (assume XGBoost + SMOTE was best in previous step)\n",
        "import joblib\n",
        "best_model = joblib.load(\"xgb_smote.pkl\")"
      ],
      "metadata": {
        "id": "0S3O7zNTdBq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2 Load data to compute explanations (weâ€™ll use the original test set)\n",
        "df = pd.read_parquet(\"creditcard_engineered.parquet\")\n",
        "X = df.drop(columns=\"Class\")\n",
        "y = df[\"Class\"]\n",
        "\n",
        "# Re-apply the same scaler as during training\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # In practice, load the scaler used during training\n",
        "\n",
        "_, X_te, _, y_te = train_test_split(X_scaled, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "# 5.3 SHAP analysis (global + local)\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "shap_values = explainer.shap_values(X_te)\n"
      ],
      "metadata": {
        "id": "Z76DJDMIdEXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5.3.1 Global feature importance plot (summary)\n",
        "plt.figure(figsize=(8, 6))\n",
        "shap.summary_plot(shap_values, X_te, feature_names=X.columns, plot_type=\"bar\", max_display=15)\n",
        "plt.title(\"SHAP Feature Importance (Top 15)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kE5ea5nZdG1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.3.2 Local explanation for a single instance\n",
        "idx = 0  # examine the first test sample\n",
        "shap.initjs()\n",
        "shap.force_plot(\n",
        "    explainer.expected_value, shap_values[idx], X_te[idx], feature_names=X.columns, matplotlib=True\n",
        ")"
      ],
      "metadata": {
        "id": "0QKCwhgNdI_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.4 LIME analysis (local)\n",
        "#    Note: We need to train a wrapper around our XGBoost model with scaler, since LIME expects raw feature values\n",
        "class WrappedModel:\n",
        "    def __init__(self, model, scaler):\n",
        "        self.model = model\n",
        "        self.scaler = scaler\n",
        "\n",
        "    def predict_proba(self, X_raw):\n",
        "        X_scaled = self.scaler.transform(X_raw)\n",
        "        return self.model.predict_proba(X_scaled)\n",
        "\n",
        "wrapped = WrappedModel(best_model, scaler)\n",
        "\n",
        "# Use LIME Tabular Explainer\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    training_data=scaler.inverse_transform(X_te),\n",
        "    feature_names=X.columns,\n",
        "    class_names=[\"Legit\", \"Fraud\"],\n",
        "    mode=\"classification\"\n",
        ")\n",
        "\n",
        "lime_exp = lime_explainer.explain_instance(\n",
        "    data_row=scaler.inverse_transform(X_te)[idx],\n",
        "    predict_fn=wrapped.predict_proba,\n",
        "    num_features=10\n",
        ")\n",
        "lime_exp.show_in_notebook(show_table=True)\n",
        "\n",
        "# 5.5 Save SHAP values and LIME explanation (optional)\n",
        "np.save(\"shap_values.npy\", shap_values)\n",
        "lime_exp.save_to_file(\"lime_exp.html\")\n"
      ],
      "metadata": {
        "id": "XsfvChGEdLwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}