{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Ensemble Model Training (Random Forest & XGBoost)"
      ],
      "metadata": {
        "id": "rdixBt4_aPQU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su5yJnTcaOGm"
      },
      "outputs": [],
      "source": [
        "# 4_ensemble_model_training.ipynb\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.1 Load resampled data and test set\n",
        "def load_parquet(name):\n",
        "    return pd.read_parquet(f\"{name}.parquet\")\n",
        "\n",
        "X_train_smote = load_parquet(\"X_train_smote\")\n",
        "y_train_smote = load_parquet(\"y_train_smote\").values.ravel()\n",
        "\n",
        "X_train_adasyn = load_parquet(\"X_train_adasyn\")\n",
        "y_train_adasyn = load_parquet(\"y_train_adasyn\").values.ravel()\n",
        "\n",
        "X_train_tomek = load_parquet(\"X_train_tomek\")\n",
        "y_train_tomek = load_parquet(\"y_train_tomek\").values.ravel()\n",
        "\n",
        "X_train_orig = load_parquet(\"X_train_orig\")\n",
        "y_train_orig = load_parquet(\"y_train_orig\").values.ravel()\n",
        "\n",
        "X_test = load_parquet(\"X_test\")\n",
        "y_test = load_parquet(\"y_test\").values.ravel()"
      ],
      "metadata": {
        "id": "qkFDb58baU00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2 Define a helper to train & evaluate\n",
        "def train_and_evaluate(model, X_tr, y_tr, X_te, y_te, label):\n",
        "    print(f\"\\n#### {label} ####\")\n",
        "    model.fit(X_tr, y_tr)\n",
        "    preds = model.predict(X_te)\n",
        "    proba = model.predict_proba(X_te)[:, 1]\n",
        "    print(classification_report(y_te, preds, digits=4))\n",
        "    auc_score = roc_auc_score(y_te, proba)\n",
        "    print(f\"AUC-ROC: {auc_score:.4f}\")\n",
        "    # Compute PR-AUC\n",
        "    precision, recall, _ = precision_recall_curve(y_te, proba)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    print(f\"AUC-PR: {pr_auc:.4f}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "0HvvgBNcaaR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3 Random Forest (using defaults as baseline, then tune)\n",
        "rf_default = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_smote = train_and_evaluate(rf_default, X_train_smote, y_train_smote, X_test, y_test, \"RF + SMOTE (default)\")\n",
        "rf_adasyn = train_and_evaluate(rf_default, X_train_adasyn, y_train_adasyn, X_test, y_test, \"RF + ADASYN (default)\")\n",
        "rf_tomek = train_and_evaluate(rf_default, X_train_tomek, y_train_tomek, X_test, y_test, \"RF + Tomek (default)\")\n",
        "rf_orig = train_and_evaluate(rf_default, X_train_orig, y_train_orig, X_test, y_test, \"RF + Original (default)\")\n"
      ],
      "metadata": {
        "id": "51DGUUISadCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.4 Hyperparameter tuning for XGBoost on the best-performing resampled set (e.g. SMOTE if that was best)\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
        "param_grid = {\n",
        "    \"max_depth\": [6, 8],\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"learning_rate\": [0.01, 0.1],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Use SMOTE set for grid search (as an example)\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=3, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train_smote, y_train_smote)"
      ],
      "metadata": {
        "id": "zy3e_j1Laf33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.6 Save the best-performing models to disk\n",
        "import joblib\n",
        "joblib.dump(rf_smote, \"rf_smote.pkl\")\n",
        "joblib.dump(xgb_smote, \"xgb_smote.pkl\")"
      ],
      "metadata": {
        "id": "hkc4DU0jagjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}